{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463ef64d-f0d4-4b9e-aaa1-5d363c05d90b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
    "# !pip install argostranslate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ac3840-ede4-41ef-96e2-a606f6f20d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25c48e7-56e0-4065-a296-e442f39c9619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 11:10:28,154\tWARNING services.py:2022 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 1895784448 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.83gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2025-05-07 11:10:28,291\tINFO worker.py:1786 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_path = \"s3://accsec-ai-prod-snitchmail/processed/phish/html_files/\"\n",
    "html_files = wr.s3.list_objects(s3_path)\n",
    "len(html_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4f942-fba4-45ee-9601-91cc2d3b1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in html_files:\n",
    "    folder = 'phish_html'\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    local_file_path = os.path.join(folder, key.split('/')[-1])\n",
    "    wr.s3.download(key, local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dd6955c-6c82-4e41-8a75-c85a5ba8c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "phish_users_file = \"s3://accsec-ai-prod-snitchmail/processed/phish/labeled_user_data.parquet\"\n",
    "os.makedirs('csv_files/w_label/', exist_ok=True)\n",
    "wr.s3.download(phish_users_file, 'csv_files/w_label/phish_user_emails.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "123cbad9-af3a-4b37-94ef-5a157e772724",
   "metadata": {},
   "outputs": [],
   "source": [
    "phish_user_emails_df = pd.read_parquet('csv_files/w_label/phish_user_emails.parquet')\n",
    "suspended_user_data = pd.read_csv('csv_files/suspended_users_20250424.csv')\n",
    "\n",
    "phish_user_emails_df['email_date'] = pd.to_datetime(phish_user_emails_df['email_date'])\n",
    "suspended_user_data['created_at'] = pd.to_datetime(suspended_user_data['created_at'])\n",
    "\n",
    "# Merge on user_id\n",
    "phish_user_575 = pd.merge(phish_user_emails_df, suspended_user_data, on='user_id', how='inner')\n",
    "\n",
    "# Filter: keep rows where email_date > (created_at - 3 days)\n",
    "phish_user_575 = phish_user_575[phish_user_575['email_date'] > (phish_user_575['created_at'] - pd.Timedelta(days=3))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b639f37-7927-44e7-a3d7-ce05b30543ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'msg_id', 'sg_event_id', 'subject', 'mime', 'email_from',\n",
       "       'email_to', 'email_date', 'originating_ip', 'originating_ip_country',\n",
       "       'lang', 's3_path', 'Content-Type', 'email_text', 'cleaned_text',\n",
       "       'translated_text', 'ealvaradob_bert_finetuned_label',\n",
       "       'ealvaradob_bert_finetuned_score', 'elslay_bert_finetuned_label',\n",
       "       'elslay_bert_finetuned_score',\n",
       "       'cybersectony_distilbert_finetuned_label',\n",
       "       'cybersectony_distilbert_finetuned_score', 'created_at'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_user_575.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c39794ed-1892-43e3-bd37-76131147dba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Argos Translate package found for af to en\n",
      "No Argos Translate package found for no to en\n",
      "No Argos Translate package found for cy to en\n",
      "No Argos Translate package found for so to en\n",
      "No Argos Translate package found for hr to en\n",
      "No Argos Translate package found for sw to en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/stanza/models/tokenize/trainer.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not close temporary folder: %s\n",
      "Could not close temporary folder: %s\n",
      "No Argos Translate package found for vi to en\n"
     ]
    }
   ],
   "source": [
    "languages = phish_user_emails_df['lang'].unique().tolist()\n",
    "import argostranslate.package\n",
    "import argostranslate.translate\n",
    "\n",
    "to_code = \"en\"\n",
    "\n",
    "for lang in languages:\n",
    "    from_code = lang.split('-')[0]\n",
    "    if from_code == 'en':\n",
    "        continue\n",
    "\n",
    "    # Download and install Argos Translate package\n",
    "    argostranslate.package.update_package_index()\n",
    "    available_packages = argostranslate.package.get_available_packages()\n",
    "    # Find all matching packages\n",
    "    matching_packages = [\n",
    "        pkg for pkg in available_packages\n",
    "        if pkg.from_code == from_code and pkg.to_code == to_code\n",
    "    ]\n",
    "    if not matching_packages:\n",
    "        print(f\"No Argos Translate package found for {from_code} to {to_code}\")\n",
    "        continue  # Skip to next language\n",
    "\n",
    "    package_to_install = matching_packages[0]\n",
    "    argostranslate.package.install_from_path(package_to_install.download())\n",
    "    \n",
    "    # Translate\n",
    "    if from_code == 'zh':\n",
    "        translatedText = argostranslate.translate.translate(\"请验证您的腾讯账户以避免使用中断\", from_code, to_code)\n",
    "        print(translatedText)\n",
    "# '¡Hola Mundo!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0cde9d1-9f2a-4ed6-8c0c-cc0636705dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argostranslate.translate\n",
    "\n",
    "# Build a dictionary of translators for each language in your DataFrame\n",
    "installed_languages = argostranslate.translate.get_installed_languages()\n",
    "to_code = \"en\"\n",
    "\n",
    "# Create a mapping: {from_lang_code: translator_object}\n",
    "translators = {}\n",
    "for lang in set(phish_user_575['lang']):\n",
    "    lang = lang.split('-')[0]\n",
    "    try:\n",
    "        from_lang = next(l for l in installed_languages if l.code == lang)\n",
    "        to_lang = next(l for l in installed_languages if l.code == to_code)\n",
    "        translators[lang] = from_lang.get_translation(to_lang)\n",
    "    except StopIteration:\n",
    "        translators[lang] = None  # No model installed for this pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "380478fe-ab40-4087-a4dc-f421401349bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fast_translate_text(text, lang):\n",
    "    lang = lang.split('-')[0]\n",
    "    translator = translators.get(lang)\n",
    "    if translator is not None:\n",
    "        try:\n",
    "            return translator.translate(text)\n",
    "        except Exception:\n",
    "            return text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65757d04-d7a7-40b3-a889-f01e7d800b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phish_user_575 = phish_user_575.drop(columns=['mime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7269adc-51db-47b5-9961-eb885d5e4074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/stanza/models/tokenize/trainer.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n"
     ]
    }
   ],
   "source": [
    "phish_user_575['subject'] = phish_user_575.apply(lambda x: fast_translate_text(x['subject'], x['lang']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c6b0a78-6172-46ec-94e6-673588d9550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/stanza/models/tokenize/trainer.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n"
     ]
    }
   ],
   "source": [
    "# Now use the fast function with apply\n",
    "phish_user_575['translated_text'] = phish_user_575.apply(\n",
    "    lambda x: fast_translate_text(x['cleaned_text'], x['lang']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53612b09-04d6-4932-a4a5-174d344e59b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(https://t.me) Using Promo Picasso to steal the competer's precision users, the social media growth program used by Top1% of the world's businesses wants to pry Facebook, Instagram, 5 billion traffic? Do you want to cut your client costs by 63% through social marketing? Multi-Account Media Matrix played this way, allowing you to support Facebook, the Instagram Multi-Account Matrix operation on the DJ 500+  * Promo Picasso: *Accessive capture of FB/IG active users, explosive billboards, hotgate owners... * Efficient customer traffic import and conversion! :: Visualize the use of security seating accounts to capture staff dynamics in real time. Click to scan login for trial (https://admin.promopicasso.com) Click to access the official channel (https://t.me) Click to consult the official passenger service (https://t.me) (https://t.me)\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_user_575[phish_user_575['lang'] == 'zh-cn'].loc[5083, 'translated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "758a5c98-4990-4272-a16e-62c09e2d632f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Document, please take immediate action, dear Sunjin.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = translators.get('zh')\n",
    "translator.translate('Document 请立即采取行动 亲爱的 Sunjin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9cdd547b-1a8f-4d73-93f8-59b1c937ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyperlink(file_id):\n",
    "    if file_id:\n",
    "        url = f\"https://drive.google.com/file/d/{file_id}/view\"\n",
    "        return f'=HYPERLINK(\"{url}\", \"HTML File\")'\n",
    "    else:\n",
    "        return \"Not Found\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8912ecd-76cb-4b0d-b6bb-67421c6b8f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = 'csv_files/w_label/ops_labeling_575.csv'\n",
    "folder_id = '17hEl7wEu-rOMSoEJLzdPICkiuYFhFlGW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94b38d1e-fdab-462c-aeb8-2740165befe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('phish_html_files_map.json', 'r') as file:\n",
    "    filename_to_fileid_map = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6f31e9b-e462-4c9d-b706-eb7ac5db7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "phish_user_575['filename'] = phish_user_575['msg_id'] + '.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce9ba969-46b1-4b67-9dcf-d79701e81a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"filename\" not in phish_user_575.columns:\n",
    "    raise ValueError(\"Input CSV must have a 'filename' column.\")\n",
    "\n",
    "file_names = phish_user_575[\"filename\"].tolist()\n",
    "\n",
    "phish_user_575[\"HTML_File_Link\"] = phish_user_575[\"filename\"].apply(lambda name: create_hyperlink(filename_to_fileid_map.get(name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4b70503-a142-412c-bdc4-d15272434677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'=HYPERLINK(\"https://drive.google.com/file/d/1meE92IXcOcxZ6rWk8pWtt0H_lw9I42Mj/view\", \"HTML File\")'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_user_575 = phish_user_575.drop(columns=[\n",
    "    'filename', 'email_text', 'cleaned_text', 'ealvaradob_bert_finetuned_label',\n",
    "       'ealvaradob_bert_finetuned_score',\n",
    "       'cybersectony_distilbert_finetuned_label',\n",
    "       'cybersectony_distilbert_finetuned_score',\n",
    "       'elslay_bert_finetuned_label', 'elslay_bert_finetuned_score'])\n",
    "phish_user_575.loc[67, 'HTML_File_Link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa622535-0ba9-478c-b723-f2d042bcf95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phish_user_575 = phish_user_575.drop(columns=[all['Content-Type', 's3_path', 'mime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "247695c4-03f3-4a4b-a985-8266173bc705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Updated CSV saved to: csv_files/w_label/ops_labeling_575.csv\n"
     ]
    }
   ],
   "source": [
    "phish_user_575.to_csv(output_csv, index=False)\n",
    "print(f\"[SUCCESS] Updated CSV saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75df473a-1cb4-49f7-ad8e-c68c0d784931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'msg_id', 'sg_event_id', 'subject', 'email_from', 'email_to',\n",
       "       'email_date', 'originating_ip', 'originating_ip_country', 'lang',\n",
       "       'translated_text', 'created_at', 'HTML_File_Link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# phish_user_emails_df['HTML_File_Link'].value_counts()\n",
    "phish_user_575.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a51ab29-5e43-409a-b102-0b400a2a230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for f in file_names:\n",
    "    if f not in filename_to_fileid_map:\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83e04444-93ac-4fd5-955e-2cb95e307d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8194278d-08db-4734-9a92-f9b4ae53f28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5562"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filename_to_fileid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68e063-f024-44a4-9213-3f2676c09e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
